## Activity Localization

* **Hollywood2Tubes**: Spot On: Action Localization from Pointly-Supervised Proposals </br>
[[Paper](https://isis-data.science.uva.nl/cgmsnoek/pub/mettes-pointly-eccv2016.pdf)][[Dataset](http://isis-data.science.uva.nl/mettes/hollywood2tubes.tar.gz)] </br>
*train: 823 videos,  1,026 action instances, 16,411 annotations; test: 884 videos, 1,086 action instances, 15,835 annotations*

* **DALY**: Human Action Localization with Sparse Spatial Supervision </br>
[[Paper](https://arxiv.org/pdf/1605.05197.pdf)][[Homepage](http://thoth.inrialpes.fr/daly/index.php)] </br>
*10 actions, 3.3M frames, 8,133 clips*

* **Action Completion**: A temporal model for Moment Detection (BMVC 2018) </br>
[[Paper](https://arxiv.org/pdf/1805.06749.pdf)][[Homepage](https://github.com/FarnooshHeidari/CompletionDetection)] </br>
*completion moments of 16 actions from three datasets: HMDB, UCF101, RGBD-AC*

* **RGBD-Action-Completion**: Beyond Action Recognition: Action Completion in RGB-D Data (BMVC 2016) </br>
[[Paper](https://dimadamen.github.io/ActionCompletion/ActionCompletion_BMVC2016.pdf)][[Homepage](https://data.bris.ac.uk/data/dataset/66qry08cv1fj1eunwxwob3fjz)] </br>
*414 complete/incomplete object interaction sequences, spanning six actions and captured using an RGB-D camera*

* **AVA**: A Video Dataset of Spatio-temporally Localized Atomic Visual Actions </br> 
[[Paper](https://arxiv.org/abs/1705.08421)][[Homepage](http://research.google.com/ava/)]</br>
*80 atomic visual actions in 430 15-minute video clips, 1.58M action labels with multiple labels per person occurring frequently*

* **AVA-Kinetics**: The AVA-Kinetics Localized Human Actions Video Dataset </br> 
[[Paper](https://arxiv.org/pdf/2005.00214.pdf)][[Homepage](http://research.google.com/ava/)]</br>
*230k clips, 80 AVA action classes*

* **HACS**: Human Action Clips and Segments Dataset for Recognition and Temporal Localization </br>
[[Paper](https://arxiv.org/pdf/1712.09374.pdf)][[Homepage](http://hacs.csail.mit.edu/)]</br>
*HACS Clips: 1.5M annotated clips sampled from 504K untrimmed videos, HACS Segments: 139K action segments densely annotated in 50K untrimmed videos spanning 200 action categories*

* **CommonLocalization**: Localizing the Common Action Among a Few Videos (ECCV 2020) </br>
[[Paper](https://isis-data.science.uva.nl/cgmsnoek/pub/yang-common-action-eccv2020.pdf)][[Homepage](https://github.com/PengWan-Yang/commonLocalization)] </br>
*few-shot common action localization, revised ActivityNet1.3 and Thumos14*

* **CommonSpaceTime**: Few-Shot Transformation of Common Actions into Time and Space (CVPR 2021) </br>
[[Paper](https://isis-data.science.uva.nl/cgmsnoek/pub/yang-common-time-space-cvpr2021.pdf)][[Homepage]()] </br>
*revised AVA and UCF101-24*

* **FineAction**: A Fined Video Dataset for Temporal Action Localization </br>
[[Paper](https://arxiv.org/pdf/2105.11107.pdf)][[Homepage](https://deeperaction.github.io/fineaction/)]</br>
*139K fined action instances densely annotated in almost 17K untrimmed videos spanning 106 action categories*

* **MUSES**: Multi-shot Temporal Event Localization: a Benchmark (CVPR 2021) </br> 
[[Paper](https://arxiv.org/pdf/2012.09434.pdf)][[Homepage](https://songbai.site/muses/)]</br>
*31,477 event instances, 716 video hours, 19 shots per instance, 176 shots per video, 25 categories, 3,697 videos*

* **MEVA**: A Large-Scale Multiview, Multimodal Video Dataset for Activity (WACV 2021) </br>
[[Paper](https://arxiv.org/pdf/2012.00914.pdf)][[Homepage](https://mevadata.org/)] </br>
*annotated 144 hours for 37 activity types, marking bounding boxes of actors and props, 38 RGB and thermal IR cameras*

* **TVSeries**: Online Action Detection (ECCV 2016) </br>
[[Paper](https://arxiv.org/pdf/1604.06506.pdf)][[Homepage](https://homes.esat.kuleuven.be/psi-archive/rdegeest/TVSeries.html)] </br>
*27 episodes from 6 popular TV series, 30 action classes, 6,231 action instances*
