## Highlight Detection
* **YouTube Highlights**: Ranking Domain-specific Highlights by Analyzing Edited Videos</br>
[[Paper](http://grail.cs.washington.edu/wp-content/uploads/2015/08/sun2014rdh.pdf)][[Homepage](https://github.com/aliensunmin/DomainSpecificHighlight)] </br>
*six domain-specific categories: surfing, skating, skiing, gymnastics, parkour, and dog. Each domain consists of around 100 videos and the total accumulated time is 1430 minutes*

* **PHD<sup>2</sup>**: Personalized Highlight Detection for Automatic GIF Creation </br>
[[Paper](https://arxiv.org/abs/1804.06604)][[Homepage](https://github.com/gifs/personalized-highlights-dataset)] </br>
*the training set contains highlights from 12,972 users, the test set contains highlights from 850 users*

* **TVSum**: Summarizing web videos using titles (CVPR 2015) </br>
[[Paper](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf)][[Homepage](https://github.com/yalesong/tvsum)] </br>
*50 videos of various genres (e.g., news, how-to, documentary, vlog, egocentric) and 1,000 annotations of shot-level importance scores obtained via crowdsourcing (20 per video)*


* **QVHIGHLIGHTS**: Detecting Moments and Highlights in Videos via Natural Language Queries (2021) </br>
[[Paper](https://arxiv.org/pdf/2107.09609.pdf)][[Homepage](https://github.com/jayleicn/moment_detr)] </br>
*over 10,000 YouTube videos, each video in the dataset is annotated with: (1) a human-written free-form NL query, (2) relevant moments in the video w.r.t. the query, and (3) five-point scale saliency scores for all query-relevant clips*
