## Video Question Answering
* **SUTD-TrafficQA**: A Question Answering Benchmark and an Efficient Network for Video Reasoning over Traffic Events </br>
[[Paper](https://arxiv.org/abs/2103.15538)][[Homepage](https://github.com/SUTDCV/SUTD-TrafficQA)] </br>
*10,080 in-the-wild videos and annotated 62,535 QA pairs*

* **R2VQ**: Recipe-to-Video Questions </br>
[[Paper]()][[Homepage](https://r2vq.org/)]</br>

* **Social-IQ**: A Question Answering Benchmark for Artificial Social Intelligence (CVPR 2019) </br>
[[Paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Zadeh_Social-IQ_A_Question_Answering_Benchmark_for_Artificial_Social_Intelligence_CVPR_2019_paper.pdf)][[Homepage](https://github.com/A2Zadeh/CMU-MultimodalSDK)] </br>
*1,250 videos, 7500 questions, 30, 000 correct answers and 22,500 incorrect answers*

* **TGIF-QA**: Toward Spatio-Temporal Reasoning in Visual Question Answering (CVPR 2017) </br>
[[Paper](https://arxiv.org/pdf/1704.04497.pdf)][[Homepage](https://github.com/YunseokJANG/tgif-qa)] </br>
*165K QA pairs for the animated GIFs from the TGIF dataset*

* **MovieQA**: Story Understanding Benchmark (CVPR 2016) </br>
[[Paper](http://movieqa.cs.toronto.edu/static/files/CVPR2016_MovieQA.pdf)][[Homepage](http://movieqa.cs.toronto.edu/home/#)]</br>
*14,944 questions, 408 movies*

* **MarioQA**: Answering Questions by Watching Gameplay Videos (ICCV 2017) </br>
[[Paper](https://openaccess.thecvf.com/content_ICCV_2017/papers/Mun_MarioQA_Answering_Questions_ICCV_2017_paper.pdf)][[Homepage](http://cvlab.postech.ac.kr/research/MarioQA/)] </br>
*13 hours of gameplays, 187,757 examples with automatically generated QA pairs; 92,874 unique QA pairs and each video clip contains 11.3 events in average*

* **TVQA**: Localized, Compositional Video Question Answering (EMNLP 2018) </br>
[[Paper](https://arxiv.org/abs/1809.01696)][[Homepage](https://www.aclweb.org/anthology/D18-1167/)] </br>
*152,545 QA pairs from 21,793 clips, spanning over 460 hours of video*
